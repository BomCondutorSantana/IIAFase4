{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projeto nº 4: Aprendizagem Automática\n",
    "\n",
    "### Introdução à Inteligência Artificial 2020/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapa 1:\n",
    "Para carregar os dados é utilizada a função load_data fornecida no módulo utilsAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris # conjunto de dados\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree # árvore de decisão\n",
    "from sklearn.neighbors import KNeighborsClassifier # k-NN\n",
    "from sklearn.model_selection import train_test_split, cross_val_score # cross-validation\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt # gráficos\n",
    "from utilsAA import * # módulo distribuido com o guião com funções auxiliares\n",
    "from sklearn import preprocessing\n",
    "\n",
    "airline_data, airline_target, airline_dclass, airline_tclass = load_data('airline.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Começamos por fazer uma decision tree primeiro\n",
    "\n",
    "Para passar de String a inteiros o que fazemos é o seguinte: vamos buscar a coluna i, que são todos elementos de uma classe de dados, vemos quantos valores diferentes existem (utilizando o unique) e guardamos os vários valores diferentes num array. De seguida vamos ver em que posição se encontra cada um desses elementos da nossa data no nosso array obtido pelo unique. A posição em que ele se encontra passa a ser o valor que vai ficar. Por exemplo: em relação a male e female, o array obtido pelo unique tem male na posição 1 e female na posição 0, portanto todos os males são substituídos 1 e female por 0.\n",
    "\n",
    "Como a nosso ver o ID do cliente não influencia a sua classificação decidimos remover a coluna com os ID's dos clientes (np.delete(array, subarray, 0 ou 1 caso seja linha ou coluna)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(airline_data[0])):\n",
    "    if type(airline_data[0][i]) == str:\n",
    "        airline_data[:,i] = encode_feature(airline_data[:,i])\n",
    "airline_tdata = airline_data\n",
    "airline_tdata = np.delete(airline_data, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melhor modelo\n",
    "Para descobrirmos o melhor modelo testámos os 2 modelos existentes, K-Vizinhos e árvore de decisão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Árvore de Decisão\n",
    "Em relação à árvore de decisão fazemos 3 for's até 20 para os vários parâmetros que vamos alterar: max_depth, min_samples_split e min_samples_leaf. Para cada valor no for, criamos uma árvore de decisão para i, j e k para os parâmetros e com o cross_val_score vamos calcular o score dessa árvore de decisão. Com os melhores valores vamos então então criar a árvore de decisão final e depois usamos o cross_val_score para obter o seu score. Como cv = 10, o cross_val_score devolve 10 scores, e o np.std(scores) dá uma média do score e o np.mean(scores) dá o erro associado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "2\n",
      "1\n",
      "0.03551128494512635\n",
      "0.8959207459207459\n"
     ]
    }
   ],
   "source": [
    "scores = None\n",
    "best = None\n",
    "best_i = 0\n",
    "best_j = 0\n",
    "best_k = 0\n",
    "for i in range(1,10):\n",
    "    for j in range(2,10):\n",
    "        for k in range(1,10):\n",
    "            dtc = DecisionTreeClassifier(criterion='entropy', max_depth = i, min_samples_split = j, \n",
    "                                         min_samples_leaf = k)\n",
    "            \n",
    "            scores = cross_val_score(dtc, X=airline_tdata, y=airline_target, cv=10, n_jobs=-1)\n",
    "            t = np.mean(scores)\n",
    "            if best == None or t > best:\n",
    "                best = t\n",
    "                best_i = i\n",
    "                best_j = j\n",
    "                best_k = k\n",
    "\n",
    "print(best_i)\n",
    "print(best_j)\n",
    "print(best_k)\n",
    "dtc = DecisionTreeClassifier(criterion='entropy', max_depth = best_i, min_samples_split = best_j, \n",
    "                                         min_samples_leaf = best_k)\n",
    "dtc.fit(airline_tdata, airline_target)\n",
    "scores = cross_val_score(dtc, X=airline_tdata, y=airline_target, cv=10, n_jobs=-1)\n",
    "print(np.std(scores))\n",
    "print(np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Vizinhos\n",
    "Em relação aos K-Vizinhos fazemos 1 for até 100 para o único parâmetro que vamos alterar: n_neighbors. Para cada valor no for, criamos um KVizinhos para o parâmetro e com o cross_val_score vamos calcular o score desse K-Vizinhos. Vamos então buscar o melhor i (o que deu um melhor resultado) e criamos um K-Vizinhos final com esse valor. Como cv = 10, o cross_val_score devolve 10 scores, e o np.std(scores) dá uma média do score e o np.mean(scores) dá o erro associado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "0.5758241758241758\n",
      "0.015327821210921386\n"
     ]
    }
   ],
   "source": [
    "scores = None\n",
    "best = None\n",
    "best_i = 0\n",
    "best_erro = None\n",
    "for i in range(1, 100): \n",
    "    clf = KNeighborsClassifier(n_neighbors=i)\n",
    "    \n",
    "    scores = cross_val_score(clf, X=airline_data, y=airline_target, cv=10, n_jobs=-1)\n",
    "    t = np.mean(scores)\n",
    "    if best == None or t > best:\n",
    "        best = t\n",
    "        best_i = i\n",
    "        best_erro = np.std(scores)\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=best_i)\n",
    "\n",
    "scores = cross_val_score(clf, X=airline_data, y=airline_target, cv=10, n_jobs=-1)\n",
    "print(best_i)\n",
    "print(np.mean(scores))\n",
    "print(np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise dos resultados\n",
    "Como é possível reparar, o melhor método para fazer previsões é a árvore de decisão 0.90% +-0.03 enquanto que o K-Vizinhos tem apenas 0.58% +- 0.01\n",
    "\n",
    "Então para fazer a previsão do teste, vamos utilizar a árvore de decisão final que foi criada utilizando os melhores valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsões\n",
    "Utilizando o método save_data e tratando a data do teste da mesma forma que foi tratada a data do airline, vamos então fazer a previsão utilizando a árvore de decisão criada a cima, não esquecendo de treinar a árvore de decisão com os dados do airline.csv\n",
    "\n",
    "O resultado é guardado no ficheiro IIA2020-proj4-29.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_dclass = load_data('test.csv', True)\n",
    "test_tdata = np.delete(test_data, 0, 1)\n",
    "\n",
    "for i in range(len(test_tdata[0])):\n",
    "    if type(test_tdata[0][i]) == str:\n",
    "        test_tdata[:,i] = encode_feature(test_tdata[:,i])\n",
    "\n",
    "\n",
    "predict = dtc.predict(test_tdata)\n",
    "\n",
    "save_data(\"IIA2021-proj4-29.csv\", predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
